process.container = '/path/to/nmt_dna_pipeline.sif'
singularity.cacheDir = '/scratch/path/to/singularity_cache'
singularity.autoMounts = true
singularity.enabled = true

tower {
	enabled = true
	accessToken = 'your token here'
}

executor {
	name = 'slurm'
	queueSize = 40
	exitReadTimeout = '60000 sec'
}

params {
	workingDir="${baseDir}"

	// where you store the raw fastq files
	rawdataDir="rawdata"

	// run FastQC or not
	run_fastqc=true

	// run methylation extraction or not
	bismark_extract=false // bismark methylation extraction is time-consuming
	allc_extract=true // generate allc files

	// extract bed files or not (for CNA analysis)
	generate_bedfile=true

	// set a loose cutoff for unique (filtered) reads for generating single-cell bam files of sciMET
	uniq_cutoff=10000

	// NMT-seq gDNA raw reads trimming parameters
	clip_DNA_R1=20
	clip_DNA_R2=20
	trim_length_DNA=36
	extra_trim_params_DNA=''
	three_prime_clip_DNA_R1=7
	three_prime_clip_DNA_R2=7

	// mapped bam file filtering
	samtools_filter_bs='-F 4 -F 256 -q 30'

	// container with downstream processes (methylpy/allcools)
	allc_container="/path/to/allc_env.sif"
	
	// reference genome file paths
	genome_folder="/path/to/bismark/genome/folder" # a folder containing BS-converted genome
	ref_fasta="/path/to/Homo_sapiens_assembly38.fasta"
	ref_fai="/path/to/Homo_sapiens_assembly38.fasta.fai"
	chromsizes="/path/to/chromosome/sizes/file" # a simple file with 1st col: chr name; 2nd col: chr size

	// local software paths
	picard="/path/to/picard.jar"	
}

process {
	clusterOptions = "--cluster your_cluster --account your_account --partition your_partition"
	
	errorStrategy = { task.exitStatus in 137..141 ? 'retry' : 'ignore' }
	
	publishDir.mode = 'copy'
	cpus = 2
	memory = 1.GB

	withName: 'trim_NMT' {
	cpus = {2 * task.attempt}
	memory = {1.GB * task.attempt}
	time = {'40m' * task.attempt}
	}

	withName: 'diagnosis' {
	cpus = {6 * task.attempt}
	memory = {30.GB * task.attempt}
	time = {'4h' * task.attempt}
	errorStrategy = 'terminate'
	}
 
	withName: 'align' {
	cpus = {6 * task.attempt}
	memory = {30.GB * task.attempt}
	time = {'3h' * task.attempt}
	}
	
	withName: 'dedup_from_bam' {
	cpus = {6 * task.attempt}
	memory = {1.GB * task.attempt}
	time = {'10m' * task.attempt}
	}
	
	withName: 'bam_dedup' {
	cpus = {6 * task.attempt}
	memory = {1.GB * task.attempt}
	time = {'10m' * task.attempt}
	}
	
	withName: 'bam_filter' {
	cpus = {3 * task.attempt}
	memory = {2.GB * task.attempt}
	time = {'10m' * task.attempt}
	}
	
	withName: 'bam_demux_process' {
	cpus = {2 * task.attempt}
	memory = {4.GB * task.attempt}
	time = {'20m' * task.attempt}
	}

	withName: 'bam_downsample' {
	cpus = {6 * task.attempt}
	memory = {5.GB * task.attempt}
	time = {'1h' * task.attempt}
	errorStrategy = 'terminate'
	}
	
	withName: 'insert_size' {
	cpus = {3 * task.attempt}
	memory = {1.GB * task.attempt}
	time = {'5m' * task.attempt}
	}

	withName: 'bs_extract_NMT' {
	cpus = {6 * task.attempt}
	memory = {8.GB * task.attempt}
	time = {'2h' * task.attempt}
	}

	withName: 'bs_extract_sciMET' {
	cpus = {6 * task.attempt}
	memory = {8.GB * task.attempt}
	time = {'2h' * task.attempt}
	}

	withName: 'extract_allc' {
	cpus = {4 * task.attempt}
	memory = {10.GB * task.attempt}
	time = {'30m' * task.attempt}
	}

	withName: 'extract_allc_contexts_NMT' {
	cpus = {2 * task.attempt}
	memory = {2.GB * task.attempt}
	time = {'15m' * task.attempt}
	}

	withName: 'extract_allc_contexts_sciMET' {
	cpus = {6 * task.attempt}
	memory = {30.GB * task.attempt}
	time = {'30m' * task.attempt}
	}
	
	withName: 'coverage_unfiltered' {
	cpus = {1 * task.attempt}
	memory = {1.GB * task.attempt}
	time = {'5m' * task.attempt}
	}

	withName: 'coverage_filtered' {
	cpus = {1 * task.attempt}
	memory = {512.MB * task.attempt}
	time = {'5m' * task.attempt}
	}

	withName: 'coverage_merge' {
	cpus = {1 * task.attempt}
	memory = {512.MB * task.attempt}
	time = {'1m' * task.attempt}
	}

	withName: 'bam_to_bed' {
	cpus = {1 * task.attempt}
	memory = {512.MB * task.attempt}
	time = {'2m' * task.attempt}
	}
}

dag {
	enabled = true
	overwrite = true
	file = 'pipeline_dag.html'
}
